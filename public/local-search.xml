<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Docker之Redis Cluster搭建</title>
    <link href="/posts/41928529/index.html"/>
    <url>/posts/41928529/index.html</url>
    
    <content type="html"><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Docker 版本 19.03.8</p><pre><code class="hljs plain">MacBook-Pro-6:~ tanxinzheng$ docker -vDocker version 19.03.8, build afacb8b</code></pre><h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><p>搭建的部署主要分为</p><ul><li>架构设计</li><li>编写Docker Compose编排文件</li><li>创建redis cluster配置文件</li><li>启动服务容器</li><li>创建Redis集群</li></ul><h3 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h3><p>redis集群模式必须要有3个主节点3个从节点才能正常启动集群模式</p><ul><li>主节点端口：7000 | 7001 | 7002</li><li>从节点端口：7003 | 7004 | 7005</li></ul><h3 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h3><p>为节省内存资源，主从节点都部署在单机实例中</p><pre><code class="hljs plain">version: &#39;2&#39;services:  cluster:    image: daocloud.io&#x2F;redis    container_name: redis-cluster    # 添加该参数后服务后台运行后，容器不会自动退出    tty: true    restart: always    # linux环境下建议使用host模式    network_mode: host    volumes:      - .&#x2F;data:&#x2F;data      - .&#x2F;config:&#x2F;etc&#x2F;redis      ports:      - &quot;7000:7000&quot;      - &quot;7001:7001&quot;      - &quot;7002:7002&quot;      - &quot;7003:7003&quot;      - &quot;7004:7004&quot;      - &quot;7005:7005&quot;    ## 必须使用宿主机ip 作为集群总线ip，否则宿主机无法访问到容器内的redis集群ip     # 也可以加在配置文件中    #  --cluster-announce-ip 172.16.65.218     command:       - &#x2F;bin&#x2F;bash       - -c       - |        redis-server &#x2F;etc&#x2F;redis&#x2F;redis_cluster_7000.conf  --cluster-announce-ip 172.16.65.218 &amp;         redis-server &#x2F;etc&#x2F;redis&#x2F;redis_cluster_7001.conf  --cluster-announce-ip 172.16.65.218 &amp;        redis-server &#x2F;etc&#x2F;redis&#x2F;redis_cluster_7002.conf  --cluster-announce-ip 172.16.65.218 &amp;        redis-server &#x2F;etc&#x2F;redis&#x2F;redis_cluster_7003.conf  --cluster-announce-ip 172.16.65.218 &amp;         redis-server &#x2F;etc&#x2F;redis&#x2F;redis_cluster_7004.conf  --cluster-announce-ip 172.16.65.218 &amp;        redis-server &#x2F;etc&#x2F;redis&#x2F;redis_cluster_7005.conf  --cluster-announce-ip 172.16.65.218</code></pre><h3 id="redis-700X-conf"><a href="#redis-700X-conf" class="headerlink" title="redis_700X.conf"></a>redis_700X.conf</h3><p>根据各端口修改配置中的端口号</p><pre><code class="hljs plain">port 7000# 绑定机器的内网IP或者公网IP,一定要设置，不要用 127.0.0.1bind 0.0.0.0# 启用集群模式cluster-enabled yes# 集群节点文件cluster-config-file nodes_7000.conf# 指定工作目录，rdb,aof持久化文件将会放在该目录下，不同实例一定要配置不同的工作目录dir &#x2F;data&#x2F;7000&#x2F;# 节点宕机发现时间，可以理解为主节点宕机后从节点升级为主节点时间cluster-node-timeout 5000# 集群广播ip#cluster-announce-ip 172.20.0.4#cluster-announce-port 7000# 开启AOF模式appendonly yes# 关闭保护模式protected-mode no# 是否后台启动daemonize no# pid file所在目录pidfile &#x2F;var&#x2F;run&#x2F;redis_7000.pid # 客户端访问密码# requirepass redis2020# 日志文件logfile &#x2F;var&#x2F;log&#x2F;redis_7001.log</code></pre><h2 id="启动Redis-Cluster"><a href="#启动Redis-Cluster" class="headerlink" title="启动Redis Cluster"></a>启动Redis Cluster</h2><pre><code class="hljs plain">docker-compose up -d</code></pre><h3 id="创建Redis集群"><a href="#创建Redis集群" class="headerlink" title="创建Redis集群"></a>创建Redis集群</h3><ul><li>进入容器<pre><code class="hljs plain">$ docker exec -it redis-cluster &#x2F;bin&#x2F;bash</code></pre></li><li>创建集群<pre><code class="hljs plain">$ redis-cli --cluster create 127.0.0.1:7000 \                           127.0.0.1:7001 \                           127.0.0.1:7002 \                           127.0.0.1:7003 \                           127.0.0.1:7004 \                           127.0.0.1:7005 \                           --cluster-replicas 1</code></pre></li></ul><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><h3 id=""><a href="#" class="headerlink" title=""></a></h3><pre><code class="hljs plain">## -c表示集群模式进入root@docker-desktop:&#x2F;data# redis-cli -c -h localhost -p 7000## 查看集群信息 cluster_state为ok则表示集群创建成功localhost:7000&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:1cluster_current_epoch:6cluster_my_epoch:3cluster_stats_messages_ping_sent:5290cluster_stats_messages_pong_sent:5299cluster_stats_messages_update_sent:1cluster_stats_messages_sent:10590cluster_stats_messages_ping_received:5294cluster_stats_messages_pong_received:5290cluster_stats_messages_meet_received:5cluster_stats_messages_update_received:3cluster_stats_messages_received:10592## 查看集群节点信息localhost:7000&gt; cluster nodes6b7f8c4767feb376a99e79068748253afcf6ea5a 127.0.0.1:7001@17001 slave ef7fdf2421427d1da29da4c1dab9e8c26ca12854 0 1607594235646 3 connected52b109a6491a2e4280b6a66642716939d0f46e89 127.0.0.1:7004@17004 slave ef7fdf2421427d1da29da4c1dab9e8c26ca12854 0 1607594236555 5 connecteddf7dcbf82ecba0ff044f2715b052674e73ec1ca6 127.0.0.1:7000@17000 myself,slave ef7fdf2421427d1da29da4c1dab9e8c26ca12854 0 1607594234000 1 connected51f5c9fb771a702933d8bc29fcd13eb41811e2bb 127.0.0.1:7005@17005 master - 0 1607594236000 6 connectedef7fdf2421427d1da29da4c1dab9e8c26ca12854 127.0.0.1:7002@17002 master - 0 1607594236657 3 connected 0-16383cf7327c9ec3b374ebc6ba3f49c6bd5e0a7098601 127.0.0.1:7003@17003 master - 0 1607594235544 4 connected</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>[1] <a href="https://redis.io/topics/cluster-tutorial" target="_blank" rel="noopener">Redis Cluster</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>redis</tag>
      
      <tag>cluster</tag>
      
      <tag>docker</tag>
      
      <tag>docker-compose</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo教程</title>
    <link href="/posts/2628717197/index.html"/>
    <url>/posts/2628717197/index.html</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><h3 id="New-draft"><a href="#New-draft" class="headerlink" title="New draft"></a>New draft</h3><pre><code>//新建草稿$ hexo new draft &quot;new draft&quot;//如果你希望强行预览草稿，更改配置文件：render_drafts: true//或者，如下方式启动server：$ hexo server --drafts//把草稿变成文章，或者页面：$ hexo publish [layout] &lt;filename&gt;</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于Github Action工作流自动部署Hexo</title>
    <link href="/posts/2231850037/index.html"/>
    <url>/posts/2231850037/index.html</url>
    
    <content type="html"><![CDATA[<h1 id="Hexo搭建"><a href="#Hexo搭建" class="headerlink" title="Hexo搭建"></a>Hexo搭建</h1><p>这段就pass了，只要这篇主要讲解Github Action部署</p><h1 id="创建github-ssh-私钥和公钥"><a href="#创建github-ssh-私钥和公钥" class="headerlink" title="创建github ssh 私钥和公钥"></a>创建github ssh 私钥和公钥</h1><p>在本地运行如下命令生成id_rsa和id_rsa.pub文件，一路回车，不要输入密码！！！不要输入密码！！！不要输入密码！！！（被这个坑的我想哭T_T，一直验证不通过）</p><pre><code class="hljs cmd">$ ssh-keygen -t rsa -C "tanxinzheng@<span class="hljs-number">139</span>.com" #此处修改为你github的注册邮箱</code></pre><h1 id="Github设置"><a href="#Github设置" class="headerlink" title="Github设置"></a>Github设置</h1><ul><li>将id_rsa私钥放入项目的settings/secures配置中</li><li>将id_rsa.pub公钥填入账号的settings/SSH keys配置中</li></ul><h1 id="创建Github-Action工作流脚本"><a href="#创建Github-Action工作流脚本" class="headerlink" title="创建Github Action工作流脚本"></a>创建Github Action工作流脚本</h1><p>在项目该目录下创建~./.github/workflows/main.yml文件，将下面的配置信息填入，并修改自己的信息即可</p><pre><code class="hljs yml"><span class="hljs-attr">name:</span> <span class="hljs-string">CI</span><span class="hljs-attr">on:</span>  <span class="hljs-attr">push:</span>    <span class="hljs-attr">branches:</span>      <span class="hljs-bullet">-</span> <span class="hljs-string">generate-source</span><span class="hljs-attr">jobs:</span>  <span class="hljs-attr">build:</span>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>    <span class="hljs-attr">steps:</span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Checkout</span> <span class="hljs-string">source</span>        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v1</span>        <span class="hljs-attr">with:</span>          <span class="hljs-attr">ref:</span> <span class="hljs-string">generate-source</span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Use</span> <span class="hljs-string">Node.js</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">matrix.node_version</span> <span class="hljs-string">&#125;&#125;</span>        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-node@v1</span>        <span class="hljs-attr">with:</span>          <span class="hljs-attr">version:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">matrix.node_version</span> <span class="hljs-string">&#125;&#125;</span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Setup</span> <span class="hljs-string">hexo</span>        <span class="hljs-attr">env:</span>          <span class="hljs-attr">ACTION_DEPLOY_KEY:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">secrets.HEXO_DEPLOY_PRI</span> <span class="hljs-string">&#125;&#125;</span>        <span class="hljs-attr">run:</span> <span class="hljs-string">|</span>          <span class="hljs-string">mkdir</span> <span class="hljs-string">-p</span> <span class="hljs-string">~/.ssh/</span>          <span class="hljs-string">echo</span> <span class="hljs-string">"$ACTION_DEPLOY_KEY"</span> <span class="hljs-string">&gt;</span> <span class="hljs-string">~/.ssh/id_rsa</span>          <span class="hljs-string">chmod</span> <span class="hljs-number">600</span> <span class="hljs-string">~/.ssh/id_rsa</span>          <span class="hljs-string">ssh-keyscan</span> <span class="hljs-string">github.com</span> <span class="hljs-string">&gt;&gt;</span> <span class="hljs-string">~/.ssh/known_hosts</span>          <span class="hljs-string">git</span> <span class="hljs-string">config</span> <span class="hljs-string">--global</span> <span class="hljs-string">user.email</span> <span class="hljs-string">"tanxinzheng@139.com"</span>          <span class="hljs-string">git</span> <span class="hljs-string">config</span> <span class="hljs-string">--global</span> <span class="hljs-string">user.name</span> <span class="hljs-string">"tanxinzheng"</span>          <span class="hljs-string">npm</span> <span class="hljs-string">install</span> <span class="hljs-string">hexo-cli</span> <span class="hljs-string">-g</span>          <span class="hljs-string">npm</span> <span class="hljs-string">install</span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Hexo</span> <span class="hljs-string">deploy</span>        <span class="hljs-attr">run:</span> <span class="hljs-string">|</span>          <span class="hljs-string">hexo</span> <span class="hljs-string">clean</span>          <span class="hljs-string">hexo</span> <span class="hljs-string">d</span></code></pre><h1 id="Github-Action执行部署"><a href="#Github-Action执行部署" class="headerlink" title="Github Action执行部署"></a>Github Action执行部署</h1><p>在Github Action页面执行即可，push之后会自动部署。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Github</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java【基础篇之HashMap及hashcode】</title>
    <link href="/posts/2936205123/index.html"/>
    <url>/posts/2936205123/index.html</url>
    
    <content type="html"><![CDATA[<h2 id="一、hashcode是什么"><a href="#一、hashcode是什么" class="headerlink" title="一、hashcode是什么"></a>一、hashcode是什么</h2><p>要理解hashcode首先要理解hash表这个概念</p><ol><li><p>哈希表<br>hash表也称散列表（Hash table），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。<br>给定表M，存在函数f(key)，对任意给定的关键字值key，代入函数后若能得到包含该关键字的hashcode是什么记录在表中的地址，则称表M为哈希(Hash）表，函数f(key)为哈希(Hash) 函数。<br>简单理解就是：在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使每个关键字和结构中一个唯一的存储位置相对应。<br>具有快速查找和插入操作的优点</p></li><li><p>hashcode<br>hashcode 通过hash函数计算得到，hashcode就是在hash表中有对应的位置<br>每个对象都有hashcode，通过将对象的物理地址转换为一个整数，将整数通过hash计算就可以得到hashcode</p><h2 id="二、hashcode的作用"><a href="#二、hashcode的作用" class="headerlink" title="二、hashcode的作用"></a>二、hashcode的作用</h2><p> HashCode的存在主要是为了查找的快捷性，HashCode是用来在散列存储结构中确定对象的存储地址的</p><p> 对于容器类设计 基本上都会涉及到hashCode。在Java中也一样，hashCode方法的主要作用是为了配合基于散列的集合一起正常运行，这样的散列集合包括HashSet、HashMap以及HashTable。</p><p>在对集合进行插入操作时，集合内时是不允许存在重复元素的，这样就引发了一个问题</p><p>如何判别在集合中是否已经存在该对象了？</p><p>首先想到的方法就是调用equals()方法，这个方法确实可行。但是如果集合中已经存在大量的数据或者更多的数据，如果采用equals方法去逐一比较，效率必然是一个问题。    此时hashCode方法的作用就体现出来了，当集合要添加新的对象时，先调用这个对象的hashCode方法，得到对应的hashcode值，实际上在HashMap的具体实现中会一个表保存已经存进去的对象的hashcode值，如果table中没有该hashcode值，它就可以直接存进去，不用再进行任何比较了；如果存在该hashcode值， 就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址，所以这里存在一个冲突解决的问题，这样一来实际调用equals方法的次数就大大降低了。</p><p> 这也就解释了为什么equals()相等，则hashCode()必须相等。如果两个对象equals()相等，则它们在哈希表(如HashSet、HashMap等)中只应该出现一次；如果hashCode()不相等，那么它们会被散列到哈希表的不同位置，哈希表中出现了不止一次。</p><pre><code>所以说hashCode方法的存在是为了减少equals方法的调用次数，从而提高程序效率。</code></pre></li></ol><h2 id="三、-hashCode-和equals"><a href="#三、-hashCode-和equals" class="headerlink" title="三、 hashCode()和equals()"></a>三、 hashCode()和equals()</h2><p>Java的基类Object中的 equals()方法用于判断两个对象是否相等，hashCode()方法用于计算对象的哈希码。equals()和hashCode()都不是final方法，都可以被重写(overwrite)</p><ol><li>equals方法<br>Object类中equals()方法实现如下</li></ol><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">equals</span><span class="hljs-params">(Object obj)</span> </span>&#123;    <span class="hljs-keyword">return</span> (<span class="hljs-keyword">this</span> == obj);&#125;</code></pre><p>通过该实现可以看出，Object类的实现采用了区分度最高的算法，即只要两个对象不是同一个对象，那么equals()一定返回false。</p><p>虽然可以重写equals()方法，但是有一些注意事项；JDK中说明了实现equals()方法应该遵守的约定</p><p>自反性：x.equals(x)必须返回true。<br>对称性：x.equals(y)与y.equals(x)的返回值必须相等。<br>传递性：x.equals(y)为true，y.equals(z)也为true，那么x.equals(z)必须为true。<br>一致性：如果对象x和y在equals()中使用的信息都没有改变，那么x.equals(y)值始终不变。<br>非null：x不是null，y为null，则x.equals(y)必须为false。<br>2. hashCode 方法<br>Object类中hashCode()方法的声明如下：</p><p>public native int hashCode();<br>可以看出，hashCode()是一个native方法，而且返回值类型是整形；实际上，该native方法将对象在内存中的地址作为哈希码返回，可以保证不同对象的返回值不同。</p><p>与equals()方法类似，hashCode()方法可以被重写。JDK中对hashCode()方法的作用，以及实现时的注意事项做了说明：</p><p>（1）hashCode()在哈希表中起作用，如java.util.HashMap。<br>（2）如果对象在equals()中使用的信息都没有改变，那么hashCode()值始终不变。<br>（3）如果两个对象使用equals()方法判断为相等，则hashCode()方法也应该相等。<br>（4）如果两个对象使用equals()方法判断为不相等，则不要求hashCode()也必须不相等；但是开发人员应该认识到，不相等的对象产生不相同的hashCode可以提高哈希表的性能。<br>重写hashcode()的原则</p><p>（1）如果重写了equals()方法，检查条件“两个对象使用equals()方法判断为相等，则hashCode()方法也应该相等”是否成立，如果不成立，则重写hashCode ()方法。<br>（2）hashCode()方法不能太过简单，否则哈希冲突过多。<br>（3）hashCode()方法不能太过复杂，否则计算复杂度过高，影响性能<br>hashCode()重写方法</p><p>《Effective Java》中提出了一种简单通用的hashCode算法：</p><p>初始化一个整形变量，为此变量赋予一个非零的常数值，比如int result = 17;</p><p>选取equals方法中用于比较的所有域（之所以只选择equals()中使用的域，是为了保证上述原则的第1条），然后针对每个域的属性进行计算：</p><p>复制代码<br>(1) 如果是boolean值，则计算f ? 1:0<br>(2) 如果是bytecharshortint,则计算(int)f<br>(3) 如果是long值，则计算(int)(f ^ (f &gt;&gt;&gt; 32))<br>(4) 如果是float值，则计算Float.floatToIntBits(f)<br>(5) 如果是double值，则计算Double.doubleToLongBits(f)，然后返回的结果是long,再用规则(3)去处理long,得到int<br>(6) 如果是对象应用，如果equals方法中采取递归调用的比较方式，那么hashCode中同样采取递归调用hashCode的方式。否则需要为这个域计算一个范式，比如当这个域的值为null的时候，那么hashCode 值为0<br>(7) 如果是数组，那么需要为每个元素当做单独的域来处理。java.util.Arrays.hashCode方法包含了8种基本类型数组和引用数组的hashCode计算，算法同上。<br>复制代码<br>最后，把每个域的散列码合并到对象的哈希码中。</p><h2 id="四、HashMap中的hash-函数"><a href="#四、HashMap中的hash-函数" class="headerlink" title="四、HashMap中的hash()函数"></a>四、HashMap中的hash()函数</h2><p>HashMap中并没有直接使用KV中K原有的hash值; 在HashMap的put、get操作时也未直接使用K中原有的hash值，而使用了一个hash()方法。让我们一起看一下这个方法</p><pre><code class="hljs plain">static final int hash(Object key) &#123;    int h;    return (key &#x3D;&#x3D; null) ? 0 : (h &#x3D; key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;</code></pre><p>这段代码类似作用是为了增加hashcode的随机性</p><p>key.hashCode()的作用是返回键值key所属类型自带的hashcode，返回的类型是int，如果直接拿散列值作为下标访问HashMap的主数组的话，考虑到int类型值的范围[-2^31 , 2^31 -1]，虽然只要hash表映射比较松散的话，碰撞几率很小，但是映射空间太大，内存放不下，所以先做对数组的长度取模运算，得到的余数才能用来访问数组下标。</p><p>hashMap源码中模运算是在这个indexFor( )函数里完成的把散列值和数组长度-1做一个”与”操作</p><p>static int indexFor(int h, int length) { return h &amp; (length-1);}<br>这也正好解释了为什么HashMap的数组长度要取2的整数幂。因为数组长度-1相当于一个“低位掩码”。“与”操作的结果就是散列值的高位全部归零，只保留低位值.以初始长度16为例，16-1=15。2进制表示是00000000 00000000 00001111。和某散列值做“与”操作如下，结果就是截取了最低的四位值。h &amp; (length - 1) 和 h % length，它俩是等价不等效的，明显位运算效率非常高。<br>  01111010 00111100 00100101<br>&amp; 00000000 00000000 00001111</p><hr><p>  00000000 00000000 00000101<br>  //高位全部归零，只保留末四位<br>but 只取后四位，即使散列值分布再松散，碰撞几率还是很大。更糟糕的是如果散列函数做的比较差吧，分布上成个等差数列啥的，恰好使最后几个低位呈现规律性重复，就比较蛋疼。</p><p>这时候 “hash”函数作用就出来了</p><p>右位移16位，正好是32bit的一半，高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。<br>设计者考虑到现在的hashCode分布的已经很不错了，而且当发生较大碰撞时也用树形存储降低了冲突。仅仅异或一下，少了系统的开销，也不会造成因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。<br>根据研究结果显示，当HashMap数组长度为512的时候，也就是用掩码取低9位的时候，在没有使用hash()的情况下，发生了103次碰撞，接近30%。而在使用了hash()之后只有92次碰撞。碰撞减少了将近10%。看来扰hash()函数在将降低碰撞上还是有功效的。<br>hashMap中 MAXIMUM_CAPACITY = 1 &lt;&lt; 30;最大为2的30次方（超过这个值就将threshold修改为Integer.MAX_VALUE（此时表的大小已经是2的31次方了），表明不进行扩容了）</p>]]></content>
    
    
    
    <tags>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux使用非root账户密钥登录SSH</title>
    <link href="/posts/2578104319/index.html"/>
    <url>/posts/2578104319/index.html</url>
    
    <content type="html"><![CDATA[<p>安装Linux/Ubuntu的阿里云ECS默认情况下是使用账号+密码通过SSH登录的，并且默认账户是root，所以这里难免会有安全隐患。<br>因此这里记录一下：Linux/Ubuntu系统怎么设置普通用户（非root用户），本教程以admin用户为例，使用秘钥登录通过SSH登录远程服务器。</p><h1 id="本地端流程"><a href="#本地端流程" class="headerlink" title="本地端流程"></a>本地端流程</h1><h2 id="检查本地SSH-Key"><a href="#检查本地SSH-Key" class="headerlink" title="检查本地SSH Key"></a>检查本地SSH Key</h2><p>检查本地是否已经存在SSH Key秘钥，输入下面的命令来检查本地是否已经存在秘钥，如果有下面结果则跳过该步，若没有那么接下来的步骤生成秘钥</p><pre><code>$ ls -a ~/.ssh.        ..        authorized_keys    id_rsa        id_rsa.pub    known_hosts</code></pre><h2 id="生成本地SSH-Key秘钥"><a href="#生成本地SSH-Key秘钥" class="headerlink" title="生成本地SSH Key秘钥"></a>生成本地SSH Key秘钥</h2><p>输入以下命令，默认会在相应路径下（~/.ssh）生成id_rsa和id_rsa.pub两个文件，如下面代码所示</p><pre><code># 注：若需要免密码登录则直接回车~$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot;   Enter file in which to save the key (/your_home_path/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /your_home_path/.ssh/id_rsa.Your public key has been saved in /your_home_path/.ssh/id_rsa.pub.The key fingerprint is:SHA256:YgZkAauw6YCWAWwvfiMgJ7zBGkVbFqgRxQ7hdet5nGY your_email@example.comThe key&apos;s randomart image is:+---[RSA 2048]----+|BO=++o           ||Bo++. .          ||oOo ..           ||+==...o .        ||X+.  o+ES        ||=X + o+.         ||.oX .            ||..               ||                 |+----[SHA256]-----+</code></pre><h1 id="服务器端流程"><a href="#服务器端流程" class="headerlink" title="服务器端流程"></a>服务器端流程</h1><p>创建普通用户<br>使用root用户操作以下命令创建普通用户：</p><h2 id="创建用户并修改密码"><a href="#创建用户并修改密码" class="headerlink" title="创建用户并修改密码"></a>创建用户并修改密码</h2><pre><code>useradd adminpasswd adminvi /etc/sudoers                                 # 增加用户su身份，编辑sudoers文件admin ALL=(ALL:ALL) ALL                         # 在最底部加入这一行，保存退出</code></pre><h2 id="添加ssh-key公钥配置"><a href="#添加ssh-key公钥配置" class="headerlink" title="添加ssh key公钥配置"></a>添加ssh key公钥配置</h2><p>使用root用户操作以下命令创建存储密钥的文件夹及文件</p><blockquote><p><font color=red><strong>注意：第三步是最重要的一步！！！</strong></font></p></blockquote><pre><code>mkdir /home/admin/.sshchmod 700 /home/admin/.ssh                       vi /home/admin/.ssh/authorized_keys            #创建authorized_keys文件，并将本地生成的id_rsa.pub的内容填入authorized_keyschmod 600 /home/admin/.ssh/authorized_keys     #设置authorized_keys权限chown -R admin:admin /home/admin/.ssh/         #修改用户组和用户所有权systemctl stop sshd                            #暂停ssh服务systemctl start sshd                           #启动ssh服务</code></pre><h2 id="设置SSH登录安全配置（可选步骤）"><a href="#设置SSH登录安全配置（可选步骤）" class="headerlink" title="设置SSH登录安全配置（可选步骤）"></a>设置SSH登录安全配置（可选步骤）</h2><blockquote><p><strong>温馨提示：SSH登录安全配置建议，使用root用户操作以下命令</strong></p></blockquote><pre><code># 编辑SSH配置文件 vi /etc/ssh/sshd_configPermitRootLogin no                             # 禁用root账号登录，该配置可不修改，避免特殊情况下需要用到rootPasswordAuthentication no                      # 禁用账号+密码登录# 保存退出后，重启ssh服务systemctl stop sshdsystemctl start sshd</code></pre><h1 id="本地验证登录"><a href="#本地验证登录" class="headerlink" title="本地验证登录"></a>本地验证登录</h1><p>因为每次记ip很麻烦，推荐使用hosts映射ip，使用别名登录。</p><h2 id="添加远端ip别名"><a href="#添加远端ip别名" class="headerlink" title="添加远端ip别名"></a>添加远端ip别名</h2><pre><code>vi /etc/hostsxxx.xxx.xxx.xxx   my-remote-server              # 添加远端ip及映射的别名：ip  别名</code></pre><h2 id="验证ssh免密登录"><a href="#验证ssh免密登录" class="headerlink" title="验证ssh免密登录"></a>验证ssh免密登录</h2><pre><code>ssh admin@xxx.xxx.xxx.xxx                       # ip远程登录ssh admin@my-remote-server                      # 别名远程登录</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【数据结构】八大数据结构简介</title>
    <link href="/posts/2827031203/index.html"/>
    <url>/posts/2827031203/index.html</url>
    
    <content type="html"><![CDATA[<h1 id="数据结构分类"><a href="#数据结构分类" class="headerlink" title="数据结构分类"></a>数据结构分类</h1><p>数据结构是指相互之间存在着一种或多种关系的数据元素的集合和该集合中数据元素之间的关系组成 。<br>常用的数据结构有：数组，栈，链表，队列，树，图，堆，散列表等，如图所示：</p><img src="/posts/2827031203/index/overview.png" srcset="/img/loading.gif" class=""><p>常见数据结构大致可分为三大类，如下所示</p><ul><li>线性表：顺序表、链表、栈和队列；</li><li>树结构：二叉树，堆、线索二叉树、红黑树、B-Tree等；</li><li>图存储结构</li></ul><h2 id="优缺点对比表"><a href="#优缺点对比表" class="headerlink" title="优缺点对比表"></a>优缺点对比表</h2><p>每一种数据结构都有着独特的数据存储方式，下面为大家介绍它们的结构和优缺点。</p><table>    <tr>        <td>数据结构</td>        <td>优点</td>        <td>缺点</td>    </tr>    <tr>        <td>数组</td>        <td>插入快，如果知道下标，可以非常快的存取</td>        <td>查找慢，删除慢，大小固定</td>    </tr>    <tr>        <td>有序数组</td>        <td>比无序的数组查找快</td>        <td>删除和插入慢，大小固定</td>    </tr>    <tr>        <td>栈</td>        <td>提供后进先出方式的存取</td>        <td>存取其他项很慢</td>    </tr>    <tr>        <td>队列</td>        <td>提供先进先出方式的存取</td>        <td>存取其他项很慢</td>    </tr>    <tr>        <td>二叉树</td>        <td>查找，插入，删除都快（如果树保持平衡）</td>        <td>删除算法复杂</td>    </tr>    <tr>        <td>红-黑树</td>        <td>查找，插入，删除都快，树总是平衡的</td>        <td>算法复杂</td>    </tr>    <tr>        <td>2-3-4树</td>        <td>查找，插入，删除都快，树总是平衡的，类似的树对磁盘存储有用</td>        <td>算法复杂</td>    </tr>    <tr>        <td>哈希表</td>        <td>如果关键字已知则存取极快，插入快</td>        <td>删除慢，如果不知道关键词则存取很慢，对存储空间使用不充分</td>    </tr>    <tr>        <td>堆</td>        <td>插入删除快，对最大数据项的存取很快</td>        <td>对其他数据项存取慢</td>    </tr>    <tr>        <td>图</td>        <td>对现实世界建模</td>        <td>有些算法慢且复杂</td>    </tr></table><h1 id="数组（Array）"><a href="#数组（Array）" class="headerlink" title="数组（Array）"></a>数组（Array）</h1><p>数组是可以再内存中连续存储多个元素的结构，在内存中的分配也是连续的，数组中的元素通过数组下标进行访问，数组下标从0开始。例如下面这段代码就是将数组的第一个元素赋值为 1。</p><pre><code>int[] data = new int[100]；data[0]  = 1;</code></pre><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>按照索引查询元素速度快</li><li>按照索引遍历数组方便</li></ul><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul><li>数组的大小固定后就无法扩容了</li><li>数组只能存储一种类型的数据</li><li>添加，删除的操作慢，因为要移动其他的元素。</li></ul><h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ul><li>频繁查询，对存储空间要求不大，很少增加和删除的情况。</li></ul><h1 id="栈（Stack）"><a href="#栈（Stack）" class="headerlink" title="栈（Stack）"></a>栈（Stack）</h1><p>栈是一种特殊的线性表，仅能在线性表的一端操作，栈顶允许操作，栈底不允许操作。 栈的特点是：先进后出，或者说是后进先出，从栈顶放入元素的操作叫入栈，取出元素叫出栈。</p><img src="/posts/2827031203/index/stack.png" srcset="/img/loading.gif" class=""><p>栈的结构就像一个集装箱，越先放进去的东西越晚才能拿出来，所以，栈常应用于实现递归功能方面的场景，例如斐波那契数列。</p><h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><p>队列与栈一样，也是一种线性表，不同的是，队列可以在一端添加元素，在另一端取出元素，也就是：先进先出。从一端放入元素的操作称为入队，取出元素为出队，示例图如下：</p><img src="/posts/2827031203/index/queue.png" srcset="/img/loading.gif" class=""><p>使用场景：因为队列先进先出的特点，在多线程阻塞队列管理中非常适用。</p><h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p>链表是物理存储单元上非连续的、非顺序的存储结构，数据元素的逻辑顺序是通过链表的指针地址实现，每个元素包含两个结点，一个是存储元素的数据域 (内存空间)，另一个是指向下一个结点地址的指针域。根据指针的指向，链表能形成不同的结构，例如单链表，双向链表，循环链表等。</p><h2 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h2><ul><li>链表是很常用的一种数据结构，不需要初始化容量，可以任意加减元素；</li><li>添加或者删除元素时只需要改变前后两个元素结点的指针域指向地址即可，所以添加，删除很快；</li></ul><h2 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h2><ul><li>因为含有大量的指针域，占用空间较大；</li><li>查找元素需要遍历链表来查找，非常耗时。</li></ul><h2 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h2><p>数据量较小，需要频繁增加，删除操作的场景</p><h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><p>树是一种数据结构，它是由n（n&gt;=1）个有限节点组成一个具有层次关系的集合。把它叫做 “树” 是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：</p><img src="/posts/2827031203/index/tree.png" srcset="/img/loading.gif" class=""><p>每个节点有零个或多个子节点；<br>没有父节点的节点称为根节点；<br>每一个非根节点有且只有一个父节点；<br>除了根节点外，每个子节点可以分为多个不相交的子树；<br>在日常的应用中，我们讨论和用的更多的是树的其中一种结构，就是二叉树。</p><p>二叉树是树的特殊一种，具有如下特点：</p><ul><li>每个结点最多有两颗子树，结点的度最大为2。</li><li>左子树和右子树是有顺序的，次序不能颠倒。</li><li>即使某结点只有一个子树，也要区分左右子树。</li></ul><p>二叉树是一种比较有用的折中方案，它添加，删除元素都很快，并且在查找方面也有很多的算法优化，所以，二叉树既有链表的好处，也有数组的好处，是两者的优化方案，在处理大批量的动态数据方面非常有用。</p><p>扩展：<br>二叉树有很多扩展的数据结构，包括平衡二叉树、红黑树、B+树等，这些数据结构二叉树的基础上衍生了很多的功能，在实际应用中广泛用到，例如mysql的数据库索引结构用的就是B+树，还有HashMap的底层源码中用到了红黑树。这些二叉树的功能强大，但算法上比较复杂，想学习的话还是需要花时间去深入的。</p><h1 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h1><p>散列表，也叫哈希表，是根据关键码和值 (key和value) 直接进行访问的数据结构，通过key和value来映射到集合中的一个位置，这样就可以很快找到集合中的对应元素。</p><img src="/posts/2827031203/index/hashtable.jpg" srcset="/img/loading.gif" class=""><p>记录的存储位置=f(key)</p><p>这里的对应关系 f 成为散列函数，又称为哈希 (hash函数)，而散列表就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里，这种存储空间可以充分利用数组的查找优势来查找元素，所以查找的速度很快。</p><p>哈希表在应用中也是比较常见的，就如Java中有些集合类就是借鉴了哈希原理构造的，例如HashMap，HashTable等，利用hash表的优势，对于集合的查找元素时非常方便的，然而，因为哈希表是基于数组衍生的数据结构，在添加删除元素方面是比较慢的，所以很多时候需要用到一种数组链表来做，也就是拉链法。拉链法是数组结合链表的一种结构，较早前的hashMap底层的存储就是采用这种结构，直到jdk1.8之后才换成了数组加红黑树的结构，其示例图如下：</p><p>从图中可以看出，左边很明显是个数组，数组的每个成员包括一个指针，指向一个链表的头，当然这个链表可能为空，也可能元素很多。我们根据元素的一些特征把元素分配到不同的链表中去，也是根据这些特征，找到正确的链表，再从链表中找出这个元素。</p><p>哈希表的应用场景很多，当然也有很多问题要考虑，比如哈希冲突的问题，如果处理的不好会浪费大量的时间，导致应用崩溃。</p><h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><img src="/posts/2827031203/index/heap.jpg" srcset="/img/loading.gif" class=""><p>堆是一种比较特殊的数据结构，可以被看做一棵树的数组对象，具有以下的性质：</p><ul><li>堆中某个节点的值总是不大于或不小于其父节点的值；</li><li>堆总是一棵完全二叉树。</li></ul><p>将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。</p><p>堆的定义如下：n个元素的序列{k1,k2,ki,…,kn}当且仅当满足下关系时，称之为堆。<br>(ki &lt;= k2i,ki &lt;= k2i+1)或者(ki &gt;= k2i,ki &gt;= k2i+1), (i = 1,2,3,4…n/2)，满足前者的表达式的成为小顶堆，满足后者表达式的为大顶堆，这两者的结构图可以用完全二叉树排列出来，示例图如下：</p><p>因为堆有序的特点，一般用来做数组中的排序，称为堆排序。</p><h1 id="图"><a href="#图" class="headerlink" title="图"></a>图</h1><p>图是由结点的有穷集合V和边的集合E组成。其中，为了与树形结构加以区别，在图结构中常常将结点称为顶点，边是顶点的有序偶对，若两个顶点之间存在一条边，就表示这两个顶点具有相邻关系。</p><p>按照顶点指向的方向可分为无向图和有向图：</p><p>图是一种比较复杂的数据结构，在存储数据上有着比较复杂和高效的算法，分别有邻接矩阵 、邻接表、十字链表、邻接多重表、边集数组等存储结构，这里不做展开，读者有兴趣可以自己学习深入。</p>]]></content>
    
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM【性能调优篇】</title>
    <link href="/posts/3097382278/index.html"/>
    <url>/posts/3097382278/index.html</url>
    
    <content type="html"><![CDATA[<p>前面我们学习了整个JVM系列，最终目标的不仅仅是了解JVM的基础知识，也是为了进行JVM性能调优做准备。这篇文章带领大家学习JVM性能调优的知识。</p><h3 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h3><p>性能调优包含多个层次，比如：架构调优、代码调优、JVM调优、数据库调优、操作系统调优等。</p><p>架构调优和代码调优是JVM调优的基础，其中架构调优是对系统影响最大的。</p><p>性能调优基本上按照以下步骤进行：明确优化目标、发现性能瓶颈、性能调优、通过监控及数据统计工具获得数据、确认是否达到目标。</p><h3 id="何时进行JVM调优"><a href="#何时进行JVM调优" class="headerlink" title="何时进行JVM调优"></a>何时进行JVM调优</h3><p>遇到以下情况，就需要考虑进行JVM调优了：</p><ul><li>Heap内存（老年代）持续上涨达到设置的最大内存值；</li><li>Full GC 次数频繁；</li><li>GC 停顿时间过长（超过1秒）；</li><li>应用出现OutOfMemory 等内存异常；</li><li>应用中有使用本地缓存且占用大量内存空间；</li><li>系统吞吐量与响应性能不高或下降。</li></ul><h3 id="JVM调优的基本原则"><a href="#JVM调优的基本原则" class="headerlink" title="JVM调优的基本原则"></a>JVM调优的基本原则</h3><p>JVM调优是一个手段，但并不一定所有问题都可以通过JVM进行调优解决，因此，在进行JVM调优时，我们要遵循一些原则：</p><ul><li>大多数的Java应用不需要进行JVM优化；</li><li>大多数导致GC问题的原因是代码层面的问题导致的（代码层面）；</li><li>上线之前，应先考虑将机器的JVM参数设置到最优；</li><li>减少创建对象的数量（代码层面）；</li><li>减少使用全局变量和大对象（代码层面）；</li><li>优先架构调优和代码调优，JVM优化是不得已的手段（代码、架构层面）；</li><li>分析GC情况优化代码比优化JVM参数更好（代码层面）；</li></ul><p>通过以上原则，我们发现，其实最有效的优化手段是架构和代码层面的优化，而JVM优化则是最后不得已的手段，也可以说是对服务器配置的最后一次“压榨”。</p><h3 id="JVM调优目标"><a href="#JVM调优目标" class="headerlink" title="JVM调优目标"></a>JVM调优目标</h3><p>调优的最终目的都是为了令应用程序使用最小的硬件消耗来承载更大的吞吐。<br>jvm调优主要是针对垃圾收集器的收集性能优化，令运行在虚拟机上的应用能够使用更少的内存以及延迟获取更大的吞吐量。</p><ul><li>延迟：GC低停顿和GC低频率；</li><li>低内存占用；</li><li>高吞吐量;</li></ul><p>其中，任何一个属性性能的提高，几乎都是以牺牲其他属性性能的损为代价的，不可兼得。具体根据在业务中的重要性确定。</p><h3 id="JVM调优量化目标"><a href="#JVM调优量化目标" class="headerlink" title="JVM调优量化目标"></a>JVM调优量化目标</h3><p>下面展示了一些JVM调优的量化目标参考实例：</p><ul><li>Heap 内存使用率 &lt;= 70%;</li><li>Old generation内存使用率&lt;= 70%;</li><li>avgpause &lt;= 1秒;</li><li>Full gc 次数0 或 avg pause interval &gt;= 24小时 ;</li></ul><p>注意：不同应用的JVM调优量化目标是不一样的。</p><h3 id="JVM调优的步骤"><a href="#JVM调优的步骤" class="headerlink" title="JVM调优的步骤"></a>JVM调优的步骤</h3><p>一般情况下，JVM调优可通过以下步骤进行：</p><ul><li>分析GC日志及dump文件，判断是否需要优化，确定瓶颈问题点；</li><li>确定JVM调优量化目标；</li><li>确定JVM调优参数（根据历史JVM参数来调整）；</li><li>依次调优内存、延迟、吞吐量等指标；</li><li>对比观察调优前后的差异；</li><li>不断的分析和调整，直到找到合适的JVM参数配置；</li><li>找到最合适的参数，将这些参数应用到所有服务器，并进行后续跟踪。</li></ul><p>以上操作步骤中，某些步骤是需要多次不断迭代完成的。一般是从满足程序的内存使用需求开始的，之后是时间延迟的要求，最后才是吞吐量的要求，要基于这个步骤来不断优化，每一个步骤都是进行下一步的基础，不可逆行之。</p><h3 id="JVM参数"><a href="#JVM参数" class="headerlink" title="JVM参数"></a>JVM参数</h3><p>JVM调优最重要的工具就是JVM参数了。先来了解一下JVM参数相关内容。</p><p>-XX 参数被称为不稳定参数，此类参数的设置很容易引起JVM 性能上的差异，使JVM存在极大的不稳定性。如果此类参数设置合理将大大提高JVM的性能及稳定性。</p><p>不稳定参数语法规则包含以下内容。</p><pre><code>布尔类型参数值：-XX:+&lt;option&gt; &apos;+&apos;表示启用该选项-XX:-&lt;option&gt; &apos;-&apos;表示关闭该选项数字类型参数值：-XX:&lt;option&gt;=&lt;number&gt;给选项设置一个数字类型值，可跟随单位，例如：&apos;m&apos;或&apos;M&apos;表示兆字节;&apos;k&apos;或&apos;K&apos;千字节;&apos;g&apos;或&apos;G&apos;千兆字节。32K与32768是相同大小的。字符串类型参数值-XX:&lt;option&gt;=&lt;string&gt;给选项设置一个字符串类型值，通常用于指定一个文件、路径或一系列命令列表。例如：-XX:HeapDumpPath=./dump.core</code></pre><h3 id="JVM参数解析及调优"><a href="#JVM参数解析及调优" class="headerlink" title="JVM参数解析及调优"></a>JVM参数解析及调优</h3><p>比如以下参数示例：</p><pre><code>-Xmx4g –Xms4g –Xmn1200m –Xss512k -XX:NewRatio=4 -XX:SurvivorRatio=8 -XX:PermSize=100m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=15</code></pre><p>上面为Java7及以前版本的示例，在Java8中永久代的参数-XX:PermSize和-XX：MaxPermSize已经失效。这在前面章节中已经讲到。</p><p>参数解析：</p><pre><code class="hljs plain">-Xmx4g：堆内存最大值为4GB。-Xms4g：初始化堆内存大小为4GB。-Xmn1200m：设置年轻代大小为1200MB。增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3&#x2F;8。-Xss512k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1MB，以前每个线程堆栈大小为256K。应根据应用线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。-XX:NewRatio&#x3D;4：设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1&#x2F;5-XX:SurvivorRatio&#x3D;8：设置年轻代中Eden区与Survivor区的大小比值。设置为8，则两个Survivor区与一个Eden区的比值为2:8，一个Survivor区占整个年轻代的1&#x2F;10-XX:PermSize&#x3D;100m：初始化永久代大小为100MB。-XX:MaxPermSize&#x3D;256m：设置持久代大小为256MB。-XX:MaxTenuringThreshold&#x3D;15：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</code></pre><p>新生代、老生代、永久代的参数，如果不进行指定，虚拟机会自动选择合适的值，同时也会基于系统的开销自动调整。</p><p>可调优参数：</p><pre><code class="hljs plain">-Xms：初始化堆内存大小，默认为物理内存的1&#x2F;64(小于1GB)。-Xmx：堆内存最大值。默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。-Xmn：新生代大小，包括Eden区与2个Survivor区。-XX:SurvivorRatio&#x3D;1：Eden区与一个Survivor区比值为1:1。-XX:MaxDirectMemorySize&#x3D;1G：直接内存。报java.lang.OutOfMemoryError: Direct buffer memory异常可以上调这个值。-XX:+DisableExplicitGC：禁止运行期显式地调用System.gc()来触发fulll GC。-XX:CMSInitiatingOccupancyFraction&#x3D;60：老年代内存回收阈值，默认值为68。-XX:ConcGCThreads&#x3D;4：CMS垃圾回收器并行线程线，推荐值为CPU核心数。-XX:ParallelGCThreads&#x3D;8：新生代并行收集器的线程数。-XX:MaxTenuringThreshold&#x3D;10：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。-XX:CMSFullGCsBeforeCompaction&#x3D;4：指定进行多少次fullGC之后，进行tenured区 内存空间压缩。-XX:CMSMaxAbortablePrecleanTime&#x3D;500：当abortable-preclean预清理阶段执行达到这个时间时就会结束。</code></pre><blockquote><p>注意: Java RMI的定时GC触发机制可通过配置-Dsun.rmi.dgc.server.gcInterval=86400来控制触发的时间。</p></blockquote><p>在设置的时候，如果关注性能开销的话，应尽量把永久代的初始值与最大值设置为同一值，因为永久代的大小调整需要进行FullGC才能实现。</p><h3 id="内存优化示例"><a href="#内存优化示例" class="headerlink" title="内存优化示例"></a>内存优化示例</h3><p>当JVM运行稳定之后，触发了FullGC我们一般会拿到如下信息:</p><p>image<br>以上gc日志中，在发生fullGC之时，整个应用的堆占用以及GC时间。为了更加精确需多次收集，计算平均值。或者是采用耗时最长的一次FullGC来进行估算。上图中，老年代空间占用在93168kb（约93MB），以此定为老年代空间的活跃数据。则其他堆空间的分配，基于以下规则来进行。</p><pre><code>java heap：参数-Xms和-Xmx，建议扩大至3-4倍FullGC后的老年代空间占用。永久代：-XX:PermSize和-XX:MaxPermSize，建议扩大至1.2-1.5倍FullGc后的永久带空间占用。新生代：-Xmn，建议扩大至1-1.5倍FullGC之后的老年代空间占用。老年代：2-3倍FullGC后的老年代空间占用。</code></pre><p>基于以上规则，则对参数定义如下：</p><pre><code class="hljs plain">java -Xms373m -Xmx373m -Xmn140m -XX:PermSize&#x3D;5m -XX:MaxPermSize&#x3D;5m</code></pre><h3 id="延迟优化示例"><a href="#延迟优化示例" class="headerlink" title="延迟优化示例"></a>延迟优化示例</h3><p>对延迟性优化，首先需要了解延迟性需求及可调优的指标有哪些。</p><ul><li>应用程序可接受的平均停滞时间: 此时间与测量的Minor</li><li>GC持续时间进行比较。可接受的Minor GC频率：Minor</li><li>GC的频率与可容忍的值进行比较。</li><li>可接受的最大停顿时间:最大停顿时间与最差情况下FullGC的持续时间进行比较。</li><li>可接受的最大停顿发生的频率：基本就是FullGC的频率。</li></ul><p>其中，平均停滞时间和最大停顿时间，对用户体验最为重要。对于上面的指标，相关数据采集包括：MinorGC的持续时间、统计MinorGC的次数、FullGC的最差持续时间、最差情况下，FullGC的频率。</p><p>image<br>如上图，Minor GC的平均持续时间0.069秒，MinorGC的频率为0.389秒一次。</p><p>新生代空间越大，Minor GC的GC时间越长，频率越低。如果想减少其持续时长，就需要减少其空间大小。如果想减小其频率，就需要加大其空间大小。</p><p>这里以减少了新生代空间10%的大小，来减小延迟时间。在此过程中，应该保持老年代和持代的大小不变化。调优后的参数如下变化:</p><pre><code class="hljs plain">java -Xms359m -Xmx359m -Xmn126m -XX:PermSize&#x3D;5m -XX:MaxPermSize&#x3D;5m</code></pre><h3 id="吞吐量调优"><a href="#吞吐量调优" class="headerlink" title="吞吐量调优"></a>吞吐量调优</h3><p>吞吐量调优主要是基于应用程序的吞吐量要求而来的，应用程序应该有一个综合的吞吐指标，这个指标基于整个应用的需求和测试而衍生出来的。</p><p>评估当前吞吐量和目标差距是否巨大，如果在20%左右，可以修改参数，加大内存，再次从头调试，如果巨大就需要从整个应用层面来考虑，设计以及目标是否一致了，重新评估吞吐目标。</p><blockquote><p>对于垃圾收集器来说，提升吞吐量的性能调优的目标就是尽可能避免或者很少发生FullGC或者Stop-The-World压缩式垃圾收集（CMS），因为这两种方式都会造成应用程序吞吐降低。尽量在MinorGC 阶段回收更多的对象，避免对象提升过快到老年代。</p></blockquote><h3 id="调优工具"><a href="#调优工具" class="headerlink" title="调优工具"></a>调优工具</h3><p>借助GCViewer日志分析工具，可以非常直观地分析出待调优点。可从以下几方面来分析：</p><ul><li>Memory,分析Totalheap、Tenuredheap、Youngheap内存占用率及其他指标，理论上内存占用率越小越好；</li><li>Pause，分析Gc pause、Fullgc pause、Total pause三个大项中各指标，理论上GC次数越少越好，GC时长越小越好；</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spring Cloud 微服务架构全链路实践</title>
    <link href="/posts/1879991184/index.html"/>
    <url>/posts/1879991184/index.html</url>
    
    <content type="html"><![CDATA[<p>Java 微服务框架选型（Dubbo 和 Spring Cloud）</p><img src="/posts/1879991184/index/1.png" srcset="/img/loading.gif" class=""><p>目前公司使用的 Spring Cloud 整个技术组件，基本包含了上面图中所包含的，不得不说，Spring Cloud 整个生态真的很强大，使用起来也很方便有效。</p><p>后面有时间再针对每个组件进行使用解读，这篇文章主要说下 Spring Cloud 架构的链路图，顺便把自己的思路整理下来，以备查阅。</p><img src="/posts/1879991184/index/2.png" srcset="/img/loading.gif" class=""><h1 id="网关请求流程"><a href="#网关请求流程" class="headerlink" title="网关请求流程"></a>网关请求流程</h1><p>在 Spring Cloud 整个组件库中，Spring Cloud Zuul 是最容易被忽视，但也是最重要的，Spring Cloud Zuul 可以和 Eureka 注册中心集成，我们目前使用 Spring Cloud Zuul 的功能如下：</p><ul><li>Filter 过滤器</li><li>Router 路由</li><li>Ribbon 负载均衡</li><li>Hystrix 熔断</li><li>Retry 重试<br>有些功能是 Spring Cloud Zuul 自带的，比如 Filter 和 Router，有些是结合 Spring Cloud 其他组件，比如 Ribbon 和 Hystrix。</li></ul><p>这里重点介绍下 Filter 过滤器，分为四个过滤类型：</p><ul><li>pre：Zuul 转发请求之前执行，我们目前的实现是AccessTokenFilter，用于 oAuth2.0 JWT 的授权验证。</li><li>route：Zuul 路由时执行，目前项目没用到。</li><li>post：Zuul 路由转发后执行，也就是已经请求成功了后端服务，我们目前的实现是CustomResponseFilter，用于统一请求格式的封装，比如 code/msg/data 等。</li><li>error：以上过滤器发生错误时执行，我们目前的实现是CustomErrorFilter，用于拦截过滤器执行的出现的错误，然后统一格式封装返回，另外，error 过滤器好像并不能捕获后端服务执行出现的错误。</li></ul><p>另外，关于 oAuth2.0 JWT 的授权验证，实现的方式有两种：</p><ul><li>授权的配置在后端服务中（每个服务都需要当作 Resource Server 进行配置，需要配置公钥，接口的授权具体配置在注解中），Zuul 只做转发，并不进行授权的验证。</li><li>授权的配置在 Zuul 中，也就是把 Zuul 当作 Resource Server，后端服务不需要进行任何处理，Zuul 中具体的实现就是AccessTokenFilter，里面的逻辑是手动解析 JWT，然后判断是否正确，以及解析出用户信息/Scope/Role，然后根据当前的请求 API，对授权 Map 中的配置进行匹配，如果匹配错误，直接抛出 401 授权错误。<br>我们目前采用的是第二种方式，这两种方式都有利有弊，关键在于自己的取舍，为什么采用第二种方式？目的就是发挥 Zuul 的作用，对外网关进行统一授权验证。</li></ul><p>关于授权 Map，里面存储了所有服务接口的配置，示例配置：</p><pre><code class="hljs plain">private static final Map ROUTE_MAPS;static &#123;    ROUTE_MAPS &#x3D; new HashMap();    ROUTE_MAPS.put(&quot;eureka-client&#x2F;home&quot;, &quot;read:ROLE_ADMIN&quot;);    ROUTE_MAPS.put(&quot;eureka-client&#x2F;user&quot;, &quot;read:ROLE_ADMIN&quot;);    ROUTE_MAPS.put(&quot;eureka-client&#x2F;error&quot;, &quot;read:ROLE_ADMIN&quot;);&#125;</code></pre><p>这是我们目前的配置，是一个静态的 Map，后面会存储在 Spring Cloud Config 配置中心，Zuul 启动时进行加载，利用 Spring Cloud Bus 动态刷新。</p><p>关于 Zuul 网关，其实还有很多需要说的，后面有机会再进行针对说明。</p><h1 id="Eureka-服务治理"><a href="#Eureka-服务治理" class="headerlink" title="Eureka 服务治理"></a>Eureka 服务治理</h1><img src="/posts/1879991184/index/3.png" srcset="/img/loading.gif" class=""><p>Eureka 遵循的是 AP 原则（服务可用性和分区容错性），是服务治理最理想的遵循 CAP 分布式原则。</p><p>Eureka 集群中的节点是彼此平级，不像 Consul 有 master/worker 之分，集群中的 Eureka 节点彼此两两注册，所以，Eureka 集群最好部署三个节点，这也是我们目前的部署方式。</p><p>另外，Eureka 的自我保护机制，可以参考这篇文章。</p><p>服务之间的相互调用，负载有两种使用方式：</p><ul><li>Feign：基于声明式，顾名思义，就是需要定义接口，就像我们平常使用对象调用一样。</li><li>Ribbon：软负载，通过往 RestTemplate 中注入负载 Handler，然后通过负载算法选取调用（通过 Eureka 获取服务注册信息）。<br>我们目前打算使用 Ribbon 负载方式，为什么？看下面代码就知道了：</li></ul><pre><code class="hljs plain">restTemplate.getForObject(&quot;http:&#x2F;&#x2F;eureka-client&#x2F;hello&quot;, String.class);</code></pre><h1 id="Config-配置中心"><a href="#Config-配置中心" class="headerlink" title="Config 配置中心"></a>Config 配置中心</h1><img src="/posts/1879991184/index/4.png" srcset="/img/loading.gif" class=""><p>我们目前配置中心使用的是 Spring Cloud Config，当然你也可以使用功能更强大的 Polly（携程开源），但 Config 目前也能满足我们的需求，存储仓库我们现在使用的是 Git。</p><p>Config 配置中心提供了数据加密功能，你可以使用 RSA 的加密方式，这样存储在 Git 中的配置都是密文形式，Config Client 获取加密配置的时候，Config Server 会自动进行解密返回。</p><p>配置中心的使用场景，我们目前主要是两个地方：</p><ul><li>项目启动的配置信息，比如数据库的连接字符串等。</li><li>业务服务的配置信息，也就是业务相关的配置。</li></ul><p>另外，需要说明的是，默认情况下，如果 Git 中的配置更新了，Config Client 不会进行更新配置，我们目前的解决方式是，使用 Spring Cloud Bus 进行动态刷新配置（Config Server 中配置），具体的流程：</p><ol><li>Git 中添加 WebHooks 脚本，比如curl -X POST <a href="http://manager1:8180/bus/refresh，当" target="_blank" rel="noopener">http://manager1:8180/bus/refresh，当</a> Git 仓库中的配置更新后，自动执行。</li><li>Config Server 中配置 Spring Cloud Bus，接受 Git 的配置刷新请求，然后利用 RabbitMQ 广播通知所有的 Config Client 订阅方，刷新配置信息。</li></ol><h1 id="Hystrix-监控"><a href="#Hystrix-监控" class="headerlink" title="Hystrix 监控"></a>Hystrix 监控</h1><img src="/posts/1879991184/index/5.png" srcset="/img/loading.gif" class=""><p>Hystrix 主要是用于服务熔断/降级/隔离处理，Hystrix 配置在调用方，当被调用方服务不可用时，触发 Hystrix 熔断，会执行指定的 Fallback 方法，进行特殊处理。</p><p>我之前以为，Hystrix 熔断的触发条件是服务不可用，也就是服务请求超时（比如服务挂掉了），但我自己测试了下，服务出现 500 错误，也会触发 Hystrix 熔断，而且会自动忽略 Hystrix 的超时时间设置。</p><p>我们目前使用 Hystrix，主要有两个地方：</p><ul><li>内部服务调用：可以对某个 API 接口进行熔断处理。</li><li>Zuul 网关使用：就是当 Zuul 路由转发调用时，但有个局限性，就是只能对服务进行熔断，并不能针对某个 API 接口熔断。</li></ul><p>上面图中，主要画的是 Hystrix 的监控流程，我们目前主要使用 RabbitMQ 进行采集传输，turbine-server 进行数据流的聚合，hystrix-dashboard 进行图形化的展示。</p><h1 id="服务调用链路"><a href="#服务调用链路" class="headerlink" title="服务调用链路"></a>服务调用链路</h1><img src="/posts/1879991184/index/6.png" srcset="/img/loading.gif" class=""><p>服务调用链路的概念，就是当服务请求发起时，记录整个请求链路的数据，以备查询。</p><p>目前市面上，几乎所有服务调用链路的实现，理论基础都是基于 Google Dapper 的那篇论文，其中最重要的概念就是 traceId 和 spanId。<br>traceId 记录整个服务链路的 ID，由首次请求方创建，服务链路中唯一。<br>spanId 记录当前服务块的 ID，由当前服务方创建。<br>parentId 记录上一个请求服务的 spanId。<br>下面我描述下，我们目前的服务调用链路过程：<br>H5 发起请求，到 Zuul 网关，Zuul 创建全局的 traceId 和自己的 spanId，然后携带这些数据到业务服务 A，并利用 Spring Cloud Sluth 传输到 RabbitMQ。<br>业务服务 A，接收到 Zuul 传输的 traceId 和 spanId，然后把 Zuul 的 spanId 设置成 parentId，并生成自己的 spanId，然后携带这些数据到业务服务 B，并利用 Spring Cloud Sluth 传输到 RabbitMQ。<br>….<br>上面图中，详细说明了整个服务调用链路的过程，这边再说下使用的技术栈：<br>Spring Cloud Sluth：和 SkyWalking 的探针概念比较类似，每个服务都进行配置，收集当然服务的请求数据（traceId 和 spanId），然后利用stream-sluth和binder-rabbit组件，将请求数据传输到 RabbitMQ。<br>Spring Cloud Zipkin：主要用于请求链路的 UI 展示，Zipkin 会从 RabbitMQ 读取请求数据，然后存储到 ElasticSearch 中，然后下次显示直接从 ElasticSearch 中读取。<br>Kibana：Kibana 也可以显示 ElasticSearch 中的请求数据，只不过不是图形化的，需要索引配置创建。</p><h1 id="ELK-日志链路"><a href="#ELK-日志链路" class="headerlink" title="ELK 日志链路"></a>ELK 日志链路</h1><img src="/posts/1879991184/index/7.png" srcset="/img/loading.gif" class=""><p>ELK 可以参考下之前的几篇文章：<br>ELK 架构之 Elasticsearch 和 Kibana 安装配置<br>ELK 架构之 Logstash 和 Filebeat 安装配置<br>ELK 架构之 Logstash 和 Filebeat 配置使用（采集过滤）<br>ELK 架构之 Elasticsearch、Kibana、Logstash 和 Filebeat 安装配置汇总（6.2.4 版本）<br>上面图中已经很详细介绍了下 ELK 的流程，ELK 默认技术栈里是没有 Filebeat 的，Logstash 用作日志收集的时候，CPU 和内存会占用资源比较大，所以我们使用轻量化的 Filebeat 进行日志的收集，Filebeat 部署在每个业务服务所在的服务器，然后将收集到的日志数据传输到 Logstash，Logstash 可以部署两到三台服务器上，用作日志的过滤和分析工作，然后再将处理后的日志数据，传输到 ElasticSearch 存储。</p><h1 id="统一格式返回"><a href="#统一格式返回" class="headerlink" title="统一格式返回"></a>统一格式返回</h1><img src="/posts/1879991184/index/8.png" srcset="/img/loading.gif" class="">]]></content>
    
    
    
    <tags>
      
      <tag>Java</tag>
      
      <tag>Spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
